# Enhancing Approximate Conformance Checking Accuracy with Hierarchical Clustering Model Behaviour Sampling

This GitHub repository contains the source code, data, and experimental results for the COMP90005 project.

The experiment result can be found at [this link](https://drive.google.com/file/d/1-Hmo3Hve3occhQ27rqf8yypqtHO5Moud/view?usp=sharing).

Our implementation consists of two main steps:

1. **Log Behavior Subset Generation**: We implemented algorithms to preprocess and construct log behavior subsets from an event log using hierarchical clustering. Specifically, the code extends the `pm4py.algo.clustering` package in PM4py by introducing the normalized weighted Levenshtein distance, enabling hierarchical clustering to group similar traces effectively. Based on clustering results, two in-cluster methods (in-cluster frequency and in-cluster medoid) select the most representative traces, forming the log behavior subset.

2. **Trace Selection and Export**: The generated log behavior subset is used to create new event logs (in `.xes` format) containing only the selected traces, which can later be analyzed using ProM for conformance checking and fitness approximation.

## Dependencies

The script requires the following Python libraries:

- `pm4py`
- `numpy`
- `scipy`
- `xml.etree.ElementTree` (standard library)

Ensure all dependencies are installed in your environment before running the script.

## Usage Instructions

The `final.py` script consists of multiple functions that together handle the complete workflow of log extraction, clustering, and export of the results. Below are details for each part:

### Step 1: Generate Clusters and Identify Representative Traces

The main function in this step, `execute_script()`, performs the following tasks:

1. **Read Event Log**: Loads an event log in `.xes` format and parses it into trace variants.
2. **Compute Distance Matrix**: Uses a custom Levenshtein distance to compute similarity among traces.
3. **Hierarchical Clustering**: Clusters traces into predefined groups and identifies representative traces (medoid and most frequent) for each cluster. Note that you need to set the cluster number, for instance, if you want 10% variants in Sepsis, you are expected to set the cluster_number equals to 85 (since the total variants number is 846, and we only choose one trace variant from one cluster, so we set 85 clusters meaning we have 85 variants here).
4. **Output Representative Traces**: Writes medoid/most frequent trace variants to an output text file (`cluster_cp-10.txt`).

### Step 2: Extract Traces Based on Representative Variants

After clustering, we generate two new `.xes` files containing traces based on the representative variants identified in Step 1:

- **Center Traces** (`incluster-medoid-10.xes`): Contains traces corresponding to medoids for each cluster.
- **Most Frequent Traces** (`incluster-frequency-10.xes`): Contains traces corresponding to the most frequent variant within each cluster.

#### Functions

- `parse_tracks_from_txt(file_path)`: Parses the output text file to retrieve representative trace indices for each cluster.
- `extract_traces_to_xml(xml_input_path, xml_output_center_path, xml_output_frequent_path, center_tracks_list, most_frequent_tracks_list)`: Reads an input `.xes` file, extracts traces based on provided track lists, and saves them as new `.xes` files.

### Step 3: Obtain Approximation value using ProM

The '.xes. file generated by Step 2 and the original xes file are put into the 'Conformance Log to Log Approximation' plug-in in ProM to obtain the approximate result. For details, refer to: [this link](https://github.com/fanisanim/AlignmentApproximator).

### Running the Script

To execute the script and generate output, simply run:

```bash
python final.py
